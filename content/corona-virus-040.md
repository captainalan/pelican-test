title: Corona Virus Diary, Part 40
date: 2020-06-24
category: News

Today I am going to ramble about "science" versus business books, pop
psychology, etc.

Many people treat "science" as a collection of facts. The next level
is to consider "science" as a collection of facts *derived through a
particular methodology*. [^1] Both of these levels of "scientific"
understanding presume a process/establishment that is good enough at
filtering good from no-good to consider humans collectively to be
"moving forward".

The next level of thinking about "science" is to consider how
authorities canonize what is(n't) "science" and how knowledge
accumulation is more about finding useful models for different things
and trying to fit them to phenomena. "Science" is a far less unified
thing than people make it out to be. Reporting "facts" is a very
difficult thing to do because "scientific facts" are always with
respect to a model.

Two places to learn more about these things:

- For an introduction, see Luke's Smith [Against Method and For
  'Pseudoscience'](https://traffic.libsyn.com/secure/notrelated/S02E01_-_Against_Method_and_For_Pseudoscience.ogg)
- For a more long-form thing, see the works of [Nassim Nicholas
  Taleb](https://fooledbyrandomness.com/)

Case Study
----------

Some neckbeard might say something like "*Qi* energy is not real".
What do they mean by this? That some traditional Chinese school of
thought is completely incoherent?

This neckbeard might reply that *Qi* cannot be *measured* with any
instrument we have. We can't observe *Qi* like we measure the
temperature with a thermometer.

To be a difficult person, you create a dataset rating video clips on
the amounts of *Qi* energy being displayed. Professional fighters
display lots of *Qi* concentration; you mark some high number. Someone
just sitting and not doing much has resting *Qi* not doing much. You
tag a few thousand video clips and then run your classification
algorithm on some new data.

Wow! Machine learning shows *Qi* exists?!??!??!?!?

Implications
------------

There's lots of useful information all over. Oftentimes, to understand
some isolated "fact" however, you need to understand some more
comprehensive system. Someone who is not trained in biology, 
chemistry, and other things is probably just driveling nonsense if
they are talking about how sodium is good/bad for the body. "Sodium"
is just a magic word to this person.

On the other hand, some people talking in terms of martial arts,
traditional medicine, etc. may be onto something. Do they have a model
of the world that helps them do whatever activities they are trying to
do?

A programer may be annoyed by many aspects of music notation. Why does
such-and-such have to be so confusing? We must respect the fact that
*Western music notation works*, as do programing languages. Both have
lots of room for improvement but they succeed at least somewhat in
some particular domain and we can state "facts" in terms of them.


Likewise, as with the machine learning example above, we can talk
about the models of psychology/business/etc. as put forth in
popular/contemporary readings. Insofar as these books are able to help
people do a better job communicating with others, getting organized,
etc., these works shouldn't just be considered as "pseudoscience".

"Fact Checking"
---------------

"Facts" only make sense with respect to some model of the world. Can
you say that XYZ *discovered the atom*? The notion of "atom" as
discussed in physics and stuff today is a very specific thing that
only exists with respect to a particular model of the world. Likewise,
when religious people speak of "the soul", a Christian might mean a
very different thing from a Buddhist or some kind of Pagan. Each
describes this term with respect to some model of the universe.

"Fact checking" is prone to be super annoying and misleading because
it presumes one (establishment-approved) view of the world and calls
things factual or not relative to that.

[^1]: E.g. falsafiable experiments
