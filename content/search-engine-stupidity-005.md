title: Search Engine Stupidity, Part 5
date: 02-18-2021
category: Interwebs

I found a video, [How Artificial Intelligence is Reshaping Humanity - With Dr.
Paula Boddington](https://youtu.be/jti77KQKYuc) (Jonathan Pageau, 02/18/2021)
which provides analysis on lots of the ideas I started to explore here in this
blog. 

Notes with timestamps follow,

- 01:00&mdash;introduction to "pop science" conception of this topic; people
  coming up with "Codes of Ethics" for AI ("Artificial Intelligence"); in order
  to do this right, you have to get more fundamental issues clarified. For
  instance, what are *people* (and what are systems we call AI)
- 05:10&mdash;AI gets "personified"; "intelligence" viewed as the pinnacle of
  human existence
- 06:10&mdash;when do we *want* to replace humans? enhance humans? clearing a
  landmine is a good use-case for not using a human. but what about *enhancing*
  humans? bias towards the "cognitive"
- 07:10&mdash;image of **golem**; popular in 19th c w/ Frankenstein and stuff.
  It is a kind of *mirror;* reflects our ideas of morality. Making people
  "better" usually means something like... adding power/capacity.
- 08:30&mdash;"AI *dethroning* humans"; anthropological issue of the place of
  humans relative to other things and creatures in the world
- 09:30&mdash;What are humans being "dethroned" at? Obviously, we have machines
  that can travel faster than people, lift heavier objects, etc. Is winning at
  chess/go/etc similar?
- 10:20&mdash;"underdog/revolutionary" story dominant in the West. *Desire* for
  AI takeover, alien takeover... cuckolding? Stories from Greeks
- 11:30&mdash;technical impossibility of "general intelligence"; beyond this
  issue is *what people believe is true*. We don't even *know* if other people
  are conscious; how can we tell that machines are? We operate in the world
  with *assumptions* about how stuff works. e.g. we assume people are more
  important than animals
- 13:50&mdash;**idols** as the *creation of a body to host intelligence*
- 14:40&mdash;we *trust* big tech in the same way the ancients trusted their
  gods; system set up so you are forced to interact with these entities
- 16:00&mdash;some people *looking forward* to "superintelligence", others
  afraid&mdash;a **false dichotomy** in that we're already in this system.
  Similar to in ancient times, through a **"priestly caste"** the will of these
  things is explained to us. Nowadays, this caste includes tech elites.
  Superior in understanding? Do you want to entrust your fate to them?
- 18:25&mdash;analogy of "ethics of weapon making"; can you impose an ethical
  system on AI? or, just recognize moral implications
- 20:20&mdash;the way we think about **privacy** is shaped by how we use
  technology. Technology is changing the way in which we interact with each
  other *in its own image*. There is a kind of parasitic relationship between
  info tech and people.
- 21:30&mdash;humans as "sex organs of the machine"; 22:30&mdash; however, we
  should also recognize the agency of tech oligarchs in operating/directing the
  machine
- 21:50&mdash;without the Internet, social media, etc the whole COVID phenomena
  we are experiencing now wouldn't be possible. Lock-downs wouldn't be
  possible.
- 24:20&mdash;"In reality, there was no lock-down. There were just middle class
  people hiding with working class people delivering stuff to them"
- 25:00&mdash;digital interactions strip lots of things from
  interactions&mdash;"body language", smells in the room, etc; we sense lots of
  things in places where we meet people
- 25:40&mdash;social media as *entertainment brought to the person-to-person level*
- 26:30&mdash;**electricity**, electricity going beyond our bodies
- 27:00&mdash;we can *sense* people looking at us. Animals too have all sorts
  of ways of perceiving. Digital tech is extremely focusing/limiting
- 28:00&mdash;digital interactions "clean up" interactions&mdash;this makes me
  think too of how all these cartoon avatars/profiles and stuff are popular.
  People are trying to get rid of the "messiness" of interactions
- 29:10&mdash;**attention** as the basis of reality; LIKE mechanism as a
  measure of attention. Quantifying attention.
- 30:20&mdash;attending to a person is a very complex thing. LIKE as a
  "currency of attention" is rather crude in that all sorts of ways of paying
  attention can be reduced to the same thing&mdash;all "likes" counted the
  same, regardless if some video/article/etc is *life-changing* or just seen in
  passing. quantity > quality
- 32:00&mdash;the system itself ("turning attention into currency") limits the
  extent to which ethics can be applied
- 33:40&mdash;reducing intelligence to quantity, mechanizing this&mdash;humans
  are treated like animals or machines
- 34:40&mdash;FB and Twitter recognized you *get* people via attention. Setting
  up a "false god" they didn't yet realize the way to optimize attention
  grabbing is by appealing to the "**lizard-brain**" (base passions)
- 36:00&mdash;intelligence comes from *humans*; human output is fed to
  machines. Horrendous jobs of **content moderation**. Actual *people* doing
  the labor; it is false to say machines are doing this. Rather, poorly paid
  people are
- 36:40&mdash;human intelligence is "farmed" and fed to machines
- 37:30&mdash;Unlike the film *The Matrix*, humans are being farmed for
  "intelligence" rather than body/heat
- 38:00&mdash;whole system is really "energy hungry"; rather than having
  endless leisure because machines do all the labor for us, what do we find?
- 39:50&mdash;Genie and the wish; people wanted something, but didn't think of
  the *side effects*
- 40:00&mdash;"hate speech" detection. Can machines detect irony? Or all the
  people that inform the machine algorithms? Can you get rid of "bias" to begin
  with? Cultural issues!
- 41:15&mdash;social media itself *fuels* the creation of "hate speech". People
  are trying to control a thing they themselves created. Anonymization,
  physical distance, and so on gives people more opportunity to unleash darker
  aspects of themselves. Efforts to control these problems (online) end up
  spilling out into "normal society". Things like "dogpiling" in comments
  sections don't occur so often in normal interactions. Unfair oustings also
  less common.
- 43:45&mdash;weird "appeal process". How can you appeal some action if you
  don't even know what you're being accused of? Opaque rules
- 44:50&mdash;people working on problems of "hate speech" have certain
  assumptions; they don't seem to realize how these rules might be applied to
  them
- 46:30&mdash;contradiction. *Unification* with the dominance of a particular
  sort of English. E-mail autocompletion. On the other hand we see
  *fragmentation*, e.g. in the multiplication of different gender categories.
  Marginalized groups have their voices amplified so they appear as larger
  portions of society than they actually comprise. This in turn leads to more
  attention *against* these people.
- 50:20&mdash;weird upside down world "created" to combat "hate"; margin has to
  be *promoted* in this inverted hierarchy. "Activists" boosted in this
  *attention economy*.
- 52:00&mdash;AI effectively boosts the power of the *leading players*; e.g.
  *What appears on the first page of Google?* people are fighting over this.
  Clearly there are *people* behind this.
- 52:50&mdash;handwavy explanation of "Oh, it's the *algorithm*"; we know this
  isn't true and that people bake their biases into things... Is there even
  such a thing as an "unbiased view of the world"?
- 53:50&mdash;problem isn't *getting rid of bias*, but rather *imposing your
  bias* on others. Refusing to acknowledge problems... imagining things are
  more "equal" when in fact there is just a *different* hierarchy.
- 55:40&mdash;are *emotions* seen as the problem? ironic because the whole
  system is based on *manipulating* emotions; AI are better because they don't
  have emotions, yet they exploit our emotions?
- 57:00&mdash;relationship of tech companies to **politics**. Tech company
  people are *unelected!* This is compounded by lock downs where we're all
  forced to look at screens for a long time each day. A totalitarian system.
- 58:20&mdash;we shouldn't despair. Some people have tried to set up
  alternatives (and then we see these got attacked); it seems control from big
  tech is extremely strong... 1:01:00&mdash;but maybe people are getting ready
  to "let out". Studying AI technology can be like a *mirror* reminding us to
  look at what we (people) are.
- 1:00:00&mdash;taken for granted that private conversations are "shady"
- 1:03:00&mdash;lots of work on AI ethics stuff is "utilitarian" or
  "consequentialist"; definitions of intelligence like "being able to take
  steps to reach goals" (**instrumentalist** type view). "Enlightenment" ideas
  of rationalism/reason, like Steven Pinker type stuff.
- 1:04:40&mdash;but we can have *lower* and *higher* goals; understanding
  intelligence in terms of goals might be fine, but we have to consider what
  sorts of goals we can have, and to identify *quality*.
- 1:09:05&mdash;we need to realize that we still have free will; we should use
  our will and also think about what sorts of lives we want to live


